{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f979b5bb-1332-4b98-b34a-746b2d02c993",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\programdata\\anaconda3\\lib\\site-packages (4.12.3)\n",
      "Requirement already satisfied: requests in c:\\programdata\\anaconda3\\lib\\site-packages (2.32.3)\n",
      "Requirement already satisfied: pandas in c:\\programdata\\anaconda3\\lib\\site-packages (2.2.2)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from beautifulsoup4) (2.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests) (2024.8.30)\n",
      "Requirement already satisfied: numpy>=1.26.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from pandas) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\programdata\\anaconda3\\lib\\site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install beautifulsoup4 requests pandas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e7764cab-0fc5-4cc9-9563-6c6ddf33fffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "17e36cc9-2b1e-44c8-bb67-66ef66c738c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_reddit(keyword=\"AI takeover\", subreddit=\"artificial\", max_posts=100):\n",
    "    import requests, pandas as pd\n",
    "    posts = []\n",
    "    after = None\n",
    "\n",
    "    while len(posts) < max_posts:\n",
    "        url = f\"https://www.reddit.com/r/{subreddit}/search.json?q={keyword}&restrict_sr=1&sort=new&limit=100\"\n",
    "        if after:\n",
    "            url += f\"&after={after}\"\n",
    "        headers = {\"User-Agent\": \"Mozilla/5.0\"}\n",
    "        res = requests.get(url, headers=headers)\n",
    "        data = res.json()\n",
    "        children = data[\"data\"][\"children\"]\n",
    "        if not children:\n",
    "            break\n",
    "        for child in children:\n",
    "            post = child[\"data\"]\n",
    "            title = post.get(\"title\", \"\")\n",
    "            selftext = post.get(\"selftext\", \"\")\n",
    "            url = \"https://reddit.com\" + post.get(\"permalink\", \"\")\n",
    "            content = selftext if selftext else title\n",
    "            posts.append({\"title\": title, \"url\": url, \"content\": content})\n",
    "        after = data[\"data\"].get(\"after\")\n",
    "        if not after:\n",
    "            break\n",
    "\n",
    "    return pd.DataFrame(posts[:max_posts])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "32214ba1-b496-4845-9aa9-225d6eb09670",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Total articles after combining and filtering: 104\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>url</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The AI Revolution Isnâ€™t Comingâ€”Itâ€™s Already He...</td>\n",
       "      <td>https://reddit.com/r/artificial/comments/1j1br...</td>\n",
       "      <td>Have you ever stopped to think about how AI is...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>One-Minute Daily AI News 9/24/2024</td>\n",
       "      <td>https://reddit.com/r/artificial/comments/1fow5...</td>\n",
       "      <td>1. â€˜Tit**A**n**I**câ€™ directorÂ **James Cameron*...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Big tech companies form new consortium to alla...</td>\n",
       "      <td>https://reddit.com/r/artificial/comments/1bvlu...</td>\n",
       "      <td>Big tech companies form new consortium to alla...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Is Devin AI Really Going To Takeover Software ...</td>\n",
       "      <td>https://reddit.com/r/artificial/comments/1bh4j...</td>\n",
       "      <td>I've been reading about Devin AI, and it seems...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Musk Demands Bigger Stake in Tesla as Price fo...</td>\n",
       "      <td>https://reddit.com/r/artificial/comments/198b1...</td>\n",
       "      <td>- Elon Musk, CEO of Tesla, has demanded that t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Yann LeCun: \"Some people are making us believe...</td>\n",
       "      <td>https://reddit.com/r/artificial/comments/1hkvr...</td>\n",
       "      <td>Yann LeCun: \"Some people are making us believe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>When AI Beats Us In Every Test We Can Create: ...</td>\n",
       "      <td>https://reddit.com/r/artificial/comments/1hkb6...</td>\n",
       "      <td>When AI Beats Us In Every Test We Can Create: ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>From o1 to o3 was just 3 months</td>\n",
       "      <td>https://reddit.com/r/artificial/comments/1hjd7...</td>\n",
       "      <td>From o1 to o3 was just 3 months</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>ARC-AGI has fallen to OpenAI's new model, o3</td>\n",
       "      <td>https://reddit.com/r/artificial/comments/1hiq1...</td>\n",
       "      <td>ARC-AGI has fallen to OpenAI's new model, o3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>AI and strategic deception: new challenges in ...</td>\n",
       "      <td>https://reddit.com/r/artificial/comments/1hhs5...</td>\n",
       "      <td>So there are two fascinating developments in A...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>103 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 title  \\\n",
       "0    The AI Revolution Isnâ€™t Comingâ€”Itâ€™s Already He...   \n",
       "1                   One-Minute Daily AI News 9/24/2024   \n",
       "2    Big tech companies form new consortium to alla...   \n",
       "3    Is Devin AI Really Going To Takeover Software ...   \n",
       "4    Musk Demands Bigger Stake in Tesla as Price fo...   \n",
       "..                                                 ...   \n",
       "98   Yann LeCun: \"Some people are making us believe...   \n",
       "99   When AI Beats Us In Every Test We Can Create: ...   \n",
       "100                    From o1 to o3 was just 3 months   \n",
       "101       ARC-AGI has fallen to OpenAI's new model, o3   \n",
       "102  AI and strategic deception: new challenges in ...   \n",
       "\n",
       "                                                   url  \\\n",
       "0    https://reddit.com/r/artificial/comments/1j1br...   \n",
       "1    https://reddit.com/r/artificial/comments/1fow5...   \n",
       "2    https://reddit.com/r/artificial/comments/1bvlu...   \n",
       "3    https://reddit.com/r/artificial/comments/1bh4j...   \n",
       "4    https://reddit.com/r/artificial/comments/198b1...   \n",
       "..                                                 ...   \n",
       "98   https://reddit.com/r/artificial/comments/1hkvr...   \n",
       "99   https://reddit.com/r/artificial/comments/1hkb6...   \n",
       "100  https://reddit.com/r/artificial/comments/1hjd7...   \n",
       "101  https://reddit.com/r/artificial/comments/1hiq1...   \n",
       "102  https://reddit.com/r/artificial/comments/1hhs5...   \n",
       "\n",
       "                                               content  \n",
       "0    Have you ever stopped to think about how AI is...  \n",
       "1    1. â€˜Tit**A**n**I**câ€™ directorÂ **James Cameron*...  \n",
       "2    Big tech companies form new consortium to alla...  \n",
       "3    I've been reading about Devin AI, and it seems...  \n",
       "4    - Elon Musk, CEO of Tesla, has demanded that t...  \n",
       "..                                                 ...  \n",
       "98   Yann LeCun: \"Some people are making us believe...  \n",
       "99   When AI Beats Us In Every Test We Can Create: ...  \n",
       "100                    From o1 to o3 was just 3 months  \n",
       "101       ARC-AGI has fallen to OpenAI's new model, o3  \n",
       "102  So there are two fascinating developments in A...  \n",
       "\n",
       "[103 rows x 3 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Scrape 3 AI-future related keywords\n",
    "df_takeover = scrape_reddit(\"AI takeover\", max_posts=50)\n",
    "df_future   = scrape_reddit(\"AI future\", max_posts=50)\n",
    "df_agi      = scrape_reddit(\"AGI\", max_posts=50)\n",
    "\n",
    "# Clean + Filter each\n",
    "df_takeover.drop_duplicates(subset=\"url\", inplace=True)\n",
    "df_future.drop_duplicates(subset=\"url\", inplace=True)\n",
    "df_agi.drop_duplicates(subset=\"url\", inplace=True)\n",
    "\n",
    "df_takeover = df_takeover[df_takeover[\"content\"].str.len() > 30]\n",
    "df_future = df_future[df_future[\"content\"].str.len() > 30]\n",
    "df_agi = df_agi[df_agi[\"content\"].str.len() > 30]\n",
    "\n",
    "# Combine all\n",
    "df_combined = pd.concat([df_takeover, df_future, df_agi]).drop_duplicates(subset=\"url\").reset_index(drop=True)\n",
    "\n",
    "print(f\" Total articles after combining and filtering: {len(df_combined)}\")\n",
    "df_combined.head(103)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "681c5fa6-bad7-494c-a13d-c907d77fe6cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "def query_ollama(prompt, model=\"mistral\"):\n",
    "    url = \"http://localhost:11434/api/generate\"\n",
    "    payload = {\n",
    "        \"model\": model,\n",
    "        \"prompt\": prompt.strip(),\n",
    "        \"stream\": False\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        response = requests.post(url, json=payload)\n",
    "        response.raise_for_status()\n",
    "        return response.json()[\"response\"]\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Error during Ollama call: {e}\")\n",
    "        return \"Summary: N/A\\nScore: 0\\nTone: Unknown\"\n",
    "\n",
    "def analyze_article(text):\n",
    "    truncated_text = text.strip().replace(\"\\n\", \" \")[:3000]  # Limit length + clean line breaks\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "You are an AI analyst. Analyze the following Reddit post about the future of AI and humanity:\n",
    "\n",
    "POST:\n",
    "{truncated_text}\n",
    "\n",
    "Tasks:\n",
    "1. Give a 2â€“3 sentence summary.\n",
    "2. Assign a score from -10 (very dangerous) to +10 (very beneficial) for the future of humanity.\n",
    "3. Classify tone as Hopeful or Fearful.\n",
    "\n",
    "Return in this exact format:\n",
    "Summary: ...\n",
    "Score: ...\n",
    "Tone: ...\n",
    "\"\"\"\n",
    "    return query_ollama(prompt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1e9460cd-3422-419b-848a-c607a83f3bec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "âš™ï¸ Running batch 1 to 10\n",
      "ğŸ” Analyzing post 1/104...\n",
      "âœ… Done in 51.15 sec\n",
      "ğŸ” Analyzing post 2/104...\n",
      "âœ… Done in 51.31 sec\n",
      "ğŸ” Analyzing post 3/104...\n",
      "âœ… Done in 18.32 sec\n",
      "ğŸ” Analyzing post 4/104...\n",
      "âœ… Done in 39.88 sec\n",
      "ğŸ” Analyzing post 5/104...\n",
      "âœ… Done in 55.78 sec\n",
      "ğŸ” Analyzing post 6/104...\n",
      "âœ… Done in 30.18 sec\n",
      "ğŸ” Analyzing post 7/104...\n",
      "âœ… Done in 39.7 sec\n",
      "ğŸ” Analyzing post 8/104...\n",
      "âœ… Done in 17.63 sec\n",
      "ğŸ” Analyzing post 9/104...\n",
      "âœ… Done in 16.46 sec\n",
      "ğŸ” Analyzing post 10/104...\n",
      "âœ… Done in 31.65 sec\n",
      "\n",
      "âš™ï¸ Running batch 11 to 20\n",
      "ğŸ” Analyzing post 11/104...\n",
      "âœ… Done in 34.32 sec\n",
      "ğŸ” Analyzing post 12/104...\n",
      "âœ… Done in 30.04 sec\n",
      "ğŸ” Analyzing post 13/104...\n",
      "âœ… Done in 33.42 sec\n",
      "ğŸ” Analyzing post 14/104...\n",
      "âœ… Done in 23.53 sec\n",
      "ğŸ” Analyzing post 15/104...\n",
      "âœ… Done in 51.24 sec\n",
      "ğŸ” Analyzing post 16/104...\n",
      "âœ… Done in 54.95 sec\n",
      "ğŸ” Analyzing post 17/104...\n",
      "âœ… Done in 58.72 sec\n",
      "ğŸ” Analyzing post 18/104...\n",
      "âœ… Done in 22.64 sec\n",
      "ğŸ” Analyzing post 19/104...\n",
      "âœ… Done in 23.72 sec\n",
      "ğŸ” Analyzing post 20/104...\n",
      "âœ… Done in 18.85 sec\n",
      "\n",
      "âš™ï¸ Running batch 21 to 30\n",
      "ğŸ” Analyzing post 21/104...\n",
      "âœ… Done in 38.68 sec\n",
      "ğŸ” Analyzing post 22/104...\n",
      "âœ… Done in 63.63 sec\n",
      "ğŸ” Analyzing post 23/104...\n",
      "âœ… Done in 34.91 sec\n",
      "ğŸ” Analyzing post 24/104...\n",
      "âœ… Done in 60.61 sec\n",
      "ğŸ” Analyzing post 25/104...\n",
      "âœ… Done in 28.86 sec\n",
      "ğŸ” Analyzing post 26/104...\n",
      "âœ… Done in 51.19 sec\n",
      "ğŸ” Analyzing post 27/104...\n",
      "âœ… Done in 29.91 sec\n",
      "ğŸ” Analyzing post 28/104...\n",
      "âœ… Done in 30.88 sec\n",
      "ğŸ” Analyzing post 29/104...\n",
      "âœ… Done in 41.43 sec\n",
      "ğŸ” Analyzing post 30/104...\n",
      "âœ… Done in 49.48 sec\n",
      "\n",
      "âš™ï¸ Running batch 31 to 40\n",
      "ğŸ” Analyzing post 31/104...\n",
      "âœ… Done in 53.12 sec\n",
      "ğŸ” Analyzing post 32/104...\n",
      "âœ… Done in 47.15 sec\n",
      "ğŸ” Analyzing post 33/104...\n",
      "âœ… Done in 29.64 sec\n",
      "ğŸ” Analyzing post 34/104...\n",
      "âœ… Done in 52.74 sec\n",
      "ğŸ” Analyzing post 35/104...\n",
      "âœ… Done in 33.6 sec\n",
      "ğŸ” Analyzing post 36/104...\n",
      "âœ… Done in 37.68 sec\n",
      "ğŸ” Analyzing post 37/104...\n",
      "âœ… Done in 52.73 sec\n",
      "ğŸ” Analyzing post 38/104...\n",
      "âœ… Done in 37.11 sec\n",
      "ğŸ” Analyzing post 39/104...\n",
      "âœ… Done in 25.79 sec\n",
      "ğŸ” Analyzing post 40/104...\n",
      "âœ… Done in 18.48 sec\n",
      "\n",
      "âš™ï¸ Running batch 41 to 50\n",
      "ğŸ” Analyzing post 41/104...\n",
      "âœ… Done in 35.18 sec\n",
      "ğŸ” Analyzing post 42/104...\n",
      "âœ… Done in 47.73 sec\n",
      "ğŸ” Analyzing post 43/104...\n",
      "âœ… Done in 39.28 sec\n",
      "ğŸ” Analyzing post 44/104...\n",
      "âœ… Done in 30.41 sec\n",
      "ğŸ” Analyzing post 45/104...\n",
      "âœ… Done in 26.47 sec\n",
      "ğŸ” Analyzing post 46/104...\n",
      "âœ… Done in 38.11 sec\n",
      "ğŸ” Analyzing post 47/104...\n",
      "âœ… Done in 45.01 sec\n",
      "ğŸ” Analyzing post 48/104...\n",
      "âœ… Done in 32.2 sec\n",
      "ğŸ” Analyzing post 49/104...\n",
      "âœ… Done in 40.28 sec\n",
      "ğŸ” Analyzing post 50/104...\n",
      "âœ… Done in 17.65 sec\n",
      "\n",
      "âš™ï¸ Running batch 51 to 60\n",
      "ğŸ” Analyzing post 51/104...\n",
      "âœ… Done in 22.72 sec\n",
      "ğŸ” Analyzing post 52/104...\n",
      "âœ… Done in 27.52 sec\n",
      "ğŸ” Analyzing post 53/104...\n",
      "âœ… Done in 31.66 sec\n",
      "ğŸ” Analyzing post 54/104...\n",
      "âœ… Done in 23.98 sec\n",
      "ğŸ” Analyzing post 55/104...\n",
      "âœ… Done in 27.09 sec\n",
      "ğŸ” Analyzing post 56/104...\n",
      "âœ… Done in 29.88 sec\n",
      "ğŸ” Analyzing post 57/104...\n",
      "âœ… Done in 48.99 sec\n",
      "ğŸ” Analyzing post 58/104...\n",
      "âœ… Done in 36.85 sec\n",
      "ğŸ” Analyzing post 59/104...\n",
      "âœ… Done in 18.91 sec\n",
      "ğŸ” Analyzing post 60/104...\n",
      "âœ… Done in 36.4 sec\n",
      "\n",
      "âš™ï¸ Running batch 61 to 70\n",
      "ğŸ” Analyzing post 61/104...\n",
      "âœ… Done in 25.56 sec\n",
      "ğŸ” Analyzing post 62/104...\n",
      "âœ… Done in 40.53 sec\n",
      "ğŸ” Analyzing post 63/104...\n",
      "âœ… Done in 53.65 sec\n",
      "ğŸ” Analyzing post 64/104...\n",
      "âœ… Done in 71.73 sec\n",
      "ğŸ” Analyzing post 65/104...\n",
      "âœ… Done in 25.13 sec\n",
      "ğŸ” Analyzing post 66/104...\n",
      "âœ… Done in 16.39 sec\n",
      "ğŸ” Analyzing post 67/104...\n",
      "âœ… Done in 51.15 sec\n",
      "ğŸ” Analyzing post 68/104...\n",
      "âœ… Done in 16.01 sec\n",
      "ğŸ” Analyzing post 69/104...\n",
      "âœ… Done in 23.58 sec\n",
      "ğŸ” Analyzing post 70/104...\n",
      "âœ… Done in 32.05 sec\n",
      "\n",
      "âš™ï¸ Running batch 71 to 80\n",
      "ğŸ” Analyzing post 71/104...\n",
      "âœ… Done in 31.2 sec\n",
      "ğŸ” Analyzing post 72/104...\n",
      "âœ… Done in 35.59 sec\n",
      "ğŸ” Analyzing post 73/104...\n",
      "âœ… Done in 38.01 sec\n",
      "ğŸ” Analyzing post 74/104...\n",
      "âœ… Done in 25.61 sec\n",
      "ğŸ” Analyzing post 75/104...\n",
      "âœ… Done in 31.0 sec\n",
      "ğŸ” Analyzing post 76/104...\n",
      "âœ… Done in 54.22 sec\n",
      "ğŸ” Analyzing post 77/104...\n",
      "âœ… Done in 29.17 sec\n",
      "ğŸ” Analyzing post 78/104...\n",
      "âœ… Done in 39.52 sec\n",
      "ğŸ” Analyzing post 79/104...\n",
      "âœ… Done in 21.16 sec\n",
      "ğŸ” Analyzing post 80/104...\n",
      "âœ… Done in 21.73 sec\n",
      "\n",
      "âš™ï¸ Running batch 81 to 90\n",
      "ğŸ” Analyzing post 81/104...\n",
      "âœ… Done in 29.35 sec\n",
      "ğŸ” Analyzing post 82/104...\n",
      "âœ… Done in 36.23 sec\n",
      "ğŸ” Analyzing post 83/104...\n",
      "âœ… Done in 36.74 sec\n",
      "ğŸ” Analyzing post 84/104...\n",
      "âœ… Done in 38.46 sec\n",
      "ğŸ” Analyzing post 85/104...\n",
      "âœ… Done in 47.43 sec\n",
      "ğŸ” Analyzing post 86/104...\n",
      "âœ… Done in 28.75 sec\n",
      "ğŸ” Analyzing post 87/104...\n",
      "âœ… Done in 15.96 sec\n",
      "ğŸ” Analyzing post 88/104...\n",
      "âœ… Done in 66.14 sec\n",
      "ğŸ” Analyzing post 89/104...\n",
      "âœ… Done in 30.63 sec\n",
      "ğŸ” Analyzing post 90/104...\n",
      "âœ… Done in 35.04 sec\n",
      "\n",
      "âš™ï¸ Running batch 91 to 100\n",
      "ğŸ” Analyzing post 91/104...\n",
      "âœ… Done in 29.62 sec\n",
      "ğŸ” Analyzing post 92/104...\n",
      "âœ… Done in 23.48 sec\n",
      "ğŸ” Analyzing post 93/104...\n",
      "âœ… Done in 49.17 sec\n",
      "ğŸ” Analyzing post 94/104...\n",
      "âœ… Done in 19.09 sec\n",
      "ğŸ” Analyzing post 95/104...\n",
      "âœ… Done in 24.75 sec\n",
      "ğŸ” Analyzing post 96/104...\n",
      "âœ… Done in 35.88 sec\n",
      "ğŸ” Analyzing post 97/104...\n",
      "âœ… Done in 31.76 sec\n",
      "ğŸ” Analyzing post 98/104...\n",
      "âœ… Done in 29.88 sec\n",
      "ğŸ” Analyzing post 99/104...\n",
      "âœ… Done in 27.94 sec\n",
      "ğŸ” Analyzing post 100/104...\n",
      "âœ… Done in 37.98 sec\n",
      "\n",
      "âš™ï¸ Running batch 101 to 104\n",
      "ğŸ” Analyzing post 101/104...\n",
      "âœ… Done in 26.39 sec\n",
      "ğŸ” Analyzing post 102/104...\n",
      "âœ… Done in 32.87 sec\n",
      "ğŸ” Analyzing post 103/104...\n",
      "âœ… Done in 50.96 sec\n",
      "ğŸ” Analyzing post 104/104...\n",
      "âœ… Done in 41.23 sec\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "results = []\n",
    "\n",
    "for i in range(0, len(df_combined), 10):\n",
    "    batch = df_combined.iloc[i:i+10].copy()\n",
    "    start_idx = i + 1\n",
    "    end_idx = i + len(batch)\n",
    "    print(f\"\\nâš™ï¸ Running batch {start_idx} to {end_idx}\")\n",
    "\n",
    "    batch_responses = []\n",
    "\n",
    "    for j, row in batch.iterrows():\n",
    "        post_num = row.name + 1\n",
    "        print(f\"ğŸ” Analyzing post {post_num}/{len(df_combined)}...\")\n",
    "        start = time.time()\n",
    "\n",
    "        try:\n",
    "            response = analyze_article(row[\"content\"])\n",
    "        except Exception as e:\n",
    "            print(f\"âŒ Error: {e}\")\n",
    "            response = \"Summary: N/A\\nScore: 0\\nTone: Unknown\"\n",
    "\n",
    "        duration = round(time.time() - start, 2)\n",
    "        print(f\"âœ… Done in {duration} sec\")\n",
    "        batch_responses.append(response)\n",
    "\n",
    "    batch[\"analysis\"] = batch_responses\n",
    "    results.append(batch)\n",
    "\n",
    "    # Auto-save progress after every batch\n",
    "    pd.concat(results).to_csv(\"ai_future_analysis_progress.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "97f2a8fa-8c1d-4e09-9dee-21bb5c29701f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>summary</th>\n",
       "      <th>score</th>\n",
       "      <th>tone</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The AI Revolution Isnâ€™t Comingâ€”Itâ€™s Already He...</td>\n",
       "      <td>The post discusses a hypothetical scenario whe...</td>\n",
       "      <td></td>\n",
       "      <td>Score: 0 (Neutral) - This scenario presents bo...</td>\n",
       "      <td>https://reddit.com/r/artificial/comments/1j1br...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>One-Minute Daily AI News 9/24/2024</td>\n",
       "      <td>The post highlights recent developments in AI,...</td>\n",
       "      <td>+6 (The advancements in AI are beneficial but ...</td>\n",
       "      <td>Neutral (The post presents information without...</td>\n",
       "      <td>https://reddit.com/r/artificial/comments/1fow5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Big tech companies form new consortium to alla...</td>\n",
       "      <td>Major tech companies have formed a consortium ...</td>\n",
       "      <td></td>\n",
       "      <td>Score: +4</td>\n",
       "      <td>https://reddit.com/r/artificial/comments/1bvlu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Is Devin AI Really Going To Takeover Software ...</td>\n",
       "      <td>The post discusses Devin AI, a new Large Langu...</td>\n",
       "      <td></td>\n",
       "      <td>Score: 0 (Neutral) - While the technology is i...</td>\n",
       "      <td>https://reddit.com/r/artificial/comments/1bh4j...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Musk Demands Bigger Stake in Tesla as Price fo...</td>\n",
       "      <td>Elon Musk, CEO of Tesla, has demanded addition...</td>\n",
       "      <td></td>\n",
       "      <td>Score: +6 (Musk's focus on AI development coul...</td>\n",
       "      <td>https://reddit.com/r/artificial/comments/198b1...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  The AI Revolution Isnâ€™t Comingâ€”Itâ€™s Already He...   \n",
       "1                 One-Minute Daily AI News 9/24/2024   \n",
       "2  Big tech companies form new consortium to alla...   \n",
       "3  Is Devin AI Really Going To Takeover Software ...   \n",
       "4  Musk Demands Bigger Stake in Tesla as Price fo...   \n",
       "\n",
       "                                             summary  \\\n",
       "0  The post discusses a hypothetical scenario whe...   \n",
       "1  The post highlights recent developments in AI,...   \n",
       "2  Major tech companies have formed a consortium ...   \n",
       "3  The post discusses Devin AI, a new Large Langu...   \n",
       "4  Elon Musk, CEO of Tesla, has demanded addition...   \n",
       "\n",
       "                                               score  \\\n",
       "0                                                      \n",
       "1  +6 (The advancements in AI are beneficial but ...   \n",
       "2                                                      \n",
       "3                                                      \n",
       "4                                                      \n",
       "\n",
       "                                                tone  \\\n",
       "0  Score: 0 (Neutral) - This scenario presents bo...   \n",
       "1  Neutral (The post presents information without...   \n",
       "2                                          Score: +4   \n",
       "3  Score: 0 (Neutral) - While the technology is i...   \n",
       "4  Score: +6 (Musk's focus on AI development coul...   \n",
       "\n",
       "                                                 url  \n",
       "0  https://reddit.com/r/artificial/comments/1j1br...  \n",
       "1  https://reddit.com/r/artificial/comments/1fow5...  \n",
       "2  https://reddit.com/r/artificial/comments/1bvlu...  \n",
       "3  https://reddit.com/r/artificial/comments/1bh4j...  \n",
       "4  https://reddit.com/r/artificial/comments/198b1...  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def parse_analysis(response):\n",
    "    try:\n",
    "        lines = response.strip().split(\"\\n\")\n",
    "        summary = lines[0].replace(\"Summary: \", \"\").strip()\n",
    "        score = lines[1].replace(\"Score: \", \"\").strip()\n",
    "        tone = lines[2].replace(\"Tone: \", \"\").strip()\n",
    "        return pd.Series([summary, score, tone])\n",
    "    except:\n",
    "        return pd.Series([\"\", \"\", \"\"])\n",
    "\n",
    "final_df = pd.concat(results).reset_index(drop=True)\n",
    "final_df[[\"summary\", \"score\", \"tone\"]] = final_df[\"analysis\"].apply(parse_analysis)\n",
    "\n",
    "# Export final CSV\n",
    "final_df.to_csv(\"final_ai_future_analysis.csv\", index=False)\n",
    "final_df[[\"title\", \"summary\", \"score\", \"tone\", \"url\"]].head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6671a4c-8fe7-48b6-b1eb-0b5627a7701e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
